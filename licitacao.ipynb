{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LicitaCon/TCE-RS: Exploratory Data Analysis\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Author: Karlson Tellicio Bezerra de Lima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ktellicio/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/ktellicio/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ktellicio/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package floresta to\n",
      "[nltk_data]     /home/ktellicio/nltk_data...\n",
      "[nltk_data]   Package floresta is already up-to-date!\n",
      "/home/ktellicio/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (2,58,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/home/ktellicio/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (2,52,54,58,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/home/ktellicio/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (2,52,53,54,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/home/ktellicio/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (53,54,59) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('floresta')\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.set_option('display.max_columns', 999)\n",
    "\n",
    "path = '2016/licitacao.csv'\n",
    "licitacao2016 = pd.read_csv(path, encoding='utf-8', header=0, sep=',', decimal=\",\", );\n",
    "path = '2017/licitacao.csv'\n",
    "licitacao2017 = pd.read_csv(path, encoding='utf-8', header=0, sep=',', decimal=\",\", );\n",
    "path = '2018/licitacao.csv'\n",
    "licitacao2018 = pd.read_csv(path, encoding='utf-8', header=0, sep=',', decimal=\",\", );\n",
    "path = '2019/licitacao.csv'\n",
    "licitacao2019 = pd.read_csv(path, encoding='utf-8', header=0, sep=',', decimal=\",\", );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "licitacao_concat.shape:  (82405, 60)\n",
      "Unique obj:  70258\n",
      "Percentage of unique objects:  85.25938960014562 %\n"
     ]
    }
   ],
   "source": [
    "dfs = [licitacao2016, licitacao2017, licitacao2018, licitacao2019]\n",
    "licitacao_concat = pd.concat(dfs, axis=0, join='outer', ignore_index = True, verify_integrity=True)\n",
    "licitacao_concat = licitacao_concat[licitacao_concat['TP_OBJETO'] == 'COM']\n",
    "licitacao_concat = licitacao_concat.dropna(how='all', axis='columns')\n",
    "\n",
    "print('licitacao_concat.shape: ', licitacao_concat.shape)\n",
    "print('Unique obj: ', licitacao_concat['DS_OBJETO'].unique().size)\n",
    "print('Percentage of unique objects: ', 100*(licitacao_concat['DS_OBJETO'].unique().size)/licitacao_concat['DS_OBJETO'].size, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "licitacao_unique.shape:  (15365, 60)\n",
      "Unique obj:  13453\n",
      "Percentage of unique objects:  87.55613407094044 %\n"
     ]
    }
   ],
   "source": [
    "# Removing x duplicated considering \n",
    "# subset of characteristics (det_duplicated) defined to identify 'item'\n",
    "det_duplicated = ['NR_LICITACAO', 'ANO_LICITACAO', 'CD_TIPO_MODALIDADE']\n",
    "licitacao_unique = licitacao_concat.drop_duplicates(subset=det_duplicated, keep='last')\n",
    "\n",
    "print('licitacao_unique.shape: ', licitacao_unique.shape)\n",
    "print('Unique obj: ', licitacao_unique['DS_OBJETO'].unique().size)\n",
    "print('Percentage of unique objects: ', 100*(licitacao_unique['DS_OBJETO'].unique().size)/licitacao_unique['DS_OBJETO'].size, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CSV saved!\n"
     ]
    }
   ],
   "source": [
    "licitacao_write = licitacao_unique\n",
    "licitacao_write.to_csv('licitacao.csv')\n",
    "print(\"New CSV saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Não usei:\n",
    "\n",
    "Aqui eu comecei a agrupar as licitacoes por 'DS_ITEM', mas logo depois vi que os arquivos item.txt já têm essa informação por meio dos códigos de família de itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "licitacao_simp = licitacao_unique.copy()\n",
    "\n",
    "\n",
    "licitacao_simp['DS_OBJETO'] = licitacao_simp['DS_OBJETO'].apply(lambda x: unidecode.unidecode(x.lower()))\n",
    "licitacao_simp['DS_OBJETO'] = licitacao_simp['DS_OBJETO'].apply(lambda x: re.sub('[0-9]|,|\\.|/|$|\\(|\\)|-|\\+|:|•|;', ' ', x))\n",
    "licitacao_simp['DS_OBJETO'] = licitacao_simp['DS_OBJETO'].apply(lambda x: re.sub(' +', ' ', x))\n",
    "licitacao_simp['DS_OBJETO'] = licitacao_simp['DS_OBJETO'].apply(lambda x: re.sub(\"aquisicao de \", '', x))\n",
    "\n",
    "print('Unique obj: ', licitacao_simp['DS_OBJETO'].unique().size)\n",
    "print('Percentage of unique objects: ', 100*(licitacao_simp['DS_OBJETO'].unique().size)/licitacao_simp['DS_OBJETO'].size, '%')\n",
    "print(licitacao_simp['DS_OBJETO'])\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords = stopwords + ['s', 'p', 'familia']\n",
    "\n",
    "licitacao_simp_clean = licitacao_simp\n",
    "licitacao_simp_clean['DS_OBJETO'] = licitacao_simp_clean['DS_OBJETO'].apply(lambda x: [word for word in x.split() if word not in stopwords])\n",
    "\n",
    "licitacao_write['DS_OBJETO'] = licitacao_simp_clean['DS_OBJETO'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "print(licitacao_simp_clean['DS_OBJETO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element exists in listof listor not?\n",
    "\n",
    "terms = [['bens', 'materiais'], \n",
    "         ['bem', 'material']]\n",
    "\n",
    "idx = []\n",
    "for obj in licitacao_simp_clean['DS_OBJETO']:\n",
    "    boo = False\n",
    "    for term in terms:\n",
    "        boo = boo or set(term).issubset(set(obj))\n",
    "    idx.append(boo)\n",
    "\n",
    "licitacao_bens = licitacao_simp_clean\n",
    "licitacao_bens = licitacao_bens[idx]   \n",
    "\n",
    "licitacao_bens.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "step =\n",
    "\n",
    "print('Objects in the top ', step, ': ', (licitacao_bens['DS_OBJETO'].value_counts().values[C*step: (C+1)*step].sum()))\n",
    "print('Percentage of unique objects in the top ', step, ': ', 100*(licitacao_bens['DS_OBJETO'].value_counts().values[C*step: (C+1)*step].sum())/licitacao_bens['DS_OBJETO'].size, '%')\n",
    "licitacao_bens['DS_OBJETO'].value_counts()[C*step: (C+1)*step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "print(licitacao_simp_clean['DS_OBJETO'])\n",
    "model = Word2Vec(licitacao_simp_clean['DS_OBJETO'], min_count=5)\n",
    "print(model)\n",
    "\n",
    "words = model.wv.index_to_key\n",
    "wv = model.wv[words]\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import networkx as nx #graphs package\n",
    "\n",
    "words_list = [word for obj in licitacao_simp_clean['DS_OBJETO'] for word in obj]\n",
    "\n",
    "le=LabelEncoder()\n",
    "le.fit(words_list)\n",
    "edges=[le.transform(x) for x in licitacao_simp_clean['DS_OBJETO']]\n",
    "\n",
    "\n",
    "G=nx.Graph() #create the graph and add edges\n",
    "for e in edges:\n",
    "    G.add_edge(e[0],e[1])\n",
    "    \n",
    "components = nx.connected_component_subgraphs(G) #analyze connected subgraphs\n",
    "comp_dict = {idx: comp.nodes() for idx, comp in enumerate(components)}\n",
    "print(comp_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from time import time\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=stopwords, sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(licitacao_simp['DS_OBJETO']).toarray()\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % final_features.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', ,])\n",
    "\n",
    "_ = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
    "np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique obj: ', licitacao_unique_obj['DS_OBJETO'].size)\n",
    "\n",
    "licitacao_unique_obj.to_csv('licitacao.csv')\n",
    "print(\"New CSV saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://docs.huihoo.com/nltk/0.9.5/guides/portuguese_en.html and\n",
    "https://www.kaggle.com/leandrodoze/examples-from-nltk-book-in-portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_tag(t):\n",
    "    if \"+\" in t:\n",
    "        return t[t.index(\"+\") + 1:]\n",
    "    else:\n",
    "        return t\n",
    "\n",
    "tsents = nltk.corpus.floresta.tagged_sents()\n",
    "tsents = [[(w.lower(),simplify_tag(t)) for (w,t) in sent] for sent in tsents if sent]\n",
    "train = tsents[100:]\n",
    "test = tsents[:100]\n",
    "\n",
    "\n",
    "\n",
    "tagger0 = nltk.DefaultTagger('n')\n",
    "tagger1 = nltk.UnigramTagger(train, backoff=tagger0)\n",
    "tagger2 = nltk.BigramTagger(train, backoff=tagger1)\n",
    "print(\" Accuracy :\", tagger2.evaluate(test))\n",
    "\n",
    "# list(tuple(str, str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "licitacao_list['DS_OBJETO'] = licitacao_list['DS_OBJETO'].apply(lambda x: [i[0] for i in tagger2.tag(x) if i[1] == 'n' or 'prop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "ss = nltk.SnowballStemmer(language = 'portuguese')\n",
    "licitacao_list['DS_OBJETO'] = licitacao_list['DS_OBJETO'].apply(lambda x: [ss.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "licitacao_list['DS_OBJETO'] = licitacao_list['DS_OBJETO'].apply(lambda x: [wn.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 0\n",
    "step = 50\n",
    "\n",
    "print('Percentage of unique objects in the top ', step, ': ', 100*(licitacao_list['DS_OBJETO'].value_counts().values[C*step: (C+1)*step].sum())/licitacao_list['DS_OBJETO'].size, '%')\n",
    "licitacao_list['DS_OBJETO'].value_counts()[C*step: (C+1)*step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
